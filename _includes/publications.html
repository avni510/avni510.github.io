<p class="title"> Papers </p>
<ul class="pubs-list">
  <li class="pubs">
    <p class="pub-title">  <a href="https://arxiv.org/abs/2410.15555"> Concept Bottleneck Models with LLM Priors </a> </p>
    <p class="pub-authors"> Jean Feng, Avni Kothari, Lucas Zier, Chandan Singh, Yan Shuo Tan</p>
    <p class="pub-date"> preprint, 2024</p>
    <p class="pub-description"> This work eliminates the need for human-annotated concepts by proposing a novel method to learn
concepts by wrapping LLMs within a Bayesian framework. This approach is highly generalizable across
various data modalities and allows for rigorous uncertainty quantification despite LLMs being prone to
error and hallucinations. </p>

    <p class="pub-title"> <a href="https://arxiv.org/abs/2308.12820"> Prediction without Preclusion: Recourse Verification with Reachable Sets </a> </p>
    <p class="pub-authors"> Avni Kothari*, Bogdan Kulynych*, Lily Weng, and Berk Ustun</p>
    <p class="pub-date"> ICLR (Spotlight), 2024</p>
    <p class="pub-description"> Individuals can be assigned predictions that they
    cannot change through actions on their features.  This paper investigates and formalizes scenarios
of predictions without recourse. We argue the importance of these scenarios for both model development and recourse
detection methods.</p>

    <p class="pub-title"> <a href="http://avni510.github.io/assets/files/amia.pdf"> Bayesian Priors From Large Language Models Make Clinical Prediction Models More Interpretable </a> </p>
    <p class="pub-authors"> Avni Kothari, Daniel J. Bennett, Seth Goldman, Elizabeth Connelly, James D. Marks, Lucas S. Zier, Jean Feng</p>
    <p class="pub-date"> AMIA Podium Abstract, 2024</p>
  </li>
</ul>
